{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02a7ed34-a641-4947-ad46-0dbb8d62a72f",
   "metadata": {},
   "source": [
    "# Predicting whether to contact a customer because they are at risk of churning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf13f94e-7612-4981-8e5e-7dd9e06280c9",
   "metadata": {},
   "source": [
    "## Part 1: Load and examine the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39199abc-9d4c-46fe-9e85-58e3e63ee24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting awswrangler\n",
      "  Using cached awswrangler-3.14.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: boto3<2,>=1.20.32 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (1.37.3)\n",
      "Requirement already satisfied: botocore<2,>=1.23.32 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (1.37.3)\n",
      "Requirement already satisfied: numpy<3.0,>=1.26 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (1.26.4)\n",
      "Requirement already satisfied: packaging<26.0,>=21.1 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (24.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (2.3.3)\n",
      "Requirement already satisfied: pyarrow<22.0.0,>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (19.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from awswrangler) (80.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /opt/conda/lib/python3.12/site-packages (from awswrangler) (4.15.0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.12/site-packages (from boto3<2,>=1.20.32->awswrangler) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /opt/conda/lib/python3.12/site-packages (from boto3<2,>=1.20.32->awswrangler) (0.11.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.12/site-packages (from botocore<2,>=1.23.32->awswrangler) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /opt/conda/lib/python3.12/site-packages (from botocore<2,>=1.23.32->awswrangler) (1.26.20)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas<3.0.0,>=1.2.0->awswrangler) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2,>=1.23.32->awswrangler) (1.17.0)\n",
      "Using cached awswrangler-3.14.0-py3-none-any.whl (380 kB)\n",
      "Installing collected packages: awswrangler\n",
      "Successfully installed awswrangler-3.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install awswrangler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06a685f9-7d0d-4ec9-8c97-594c5f3242f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import awswrangler as wr  # For efficient S3 reads/writes\n",
    "from time import sleep\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Setup\n",
    "data_bucket = 'machine-learning-for-interview'\n",
    "subfolder = 'chapter-03'\n",
    "dataset = 'churn_data.csv'\n",
    "processed_subfolder = f'{subfolder}/processed'  # For clarity\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = Session(boto3.Session())  # Explicit session for reproducibility\n",
    "region = sess.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68199ffb-e2d5-40fc-81a4-416d906dfde3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   churned  id  customer_code                        co_name  total_spend  \\\n",
      "0        0   1           1826  Hoffman Martinez and Chandler     68567.34   \n",
      "1        0   2            772         Lee Martin and Escobar     74335.27   \n",
      "2        0   3            479       Hobbs Mcdaniel and Baker     48746.22   \n",
      "3        0   4           1692                Williams-Harris     64416.70   \n",
      "4        0   5           2578                    Beck-Snyder     71623.20   \n",
      "\n",
      "   week_minus_4  week_minus_3  week_minus_2  last_week  4-3_delta  3-2_delta  \\\n",
      "0          0.81          0.02          0.74       1.45      -0.79       0.72   \n",
      "1          1.87          1.02          1.29       1.19      -0.85       0.27   \n",
      "2          1.21          0.70          1.04       2.12      -0.51       0.34   \n",
      "3          0.75          2.08          2.40       2.02       1.33       0.32   \n",
      "4          2.33          0.66          1.97       1.60      -1.67       1.31   \n",
      "\n",
      "   2-1_delta  \n",
      "0       0.71  \n",
      "1      -0.10  \n",
      "2       1.08  \n",
      "3      -0.38  \n",
      "4      -0.37  \n"
     ]
    }
   ],
   "source": [
    "# Load data with AWS Data Wrangler (faster than s3fs)\n",
    "s3_path = f's3://{data_bucket}/{subfolder}/{dataset}'\n",
    "df = wr.s3.read_csv(path=s3_path, use_threads=True)\n",
    "print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b371ebd8-b1fa-4ad1-80eb-35eaba7749b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 2999\n",
      "churned\n",
      "0    2833\n",
      "1     166\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of rows in dataset: {df.shape[0]}')\n",
    "print(df['churned'].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b19d81c-5524-4aad-984f-1d5553434ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 2: Get the data into the right shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2d0a935-01e6-4650-975b-e6dfffcfa2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   churned  total_spend  week_minus_4  week_minus_3  week_minus_2  last_week  \\\n",
      "0        0     68567.34          0.81          0.02          0.74       1.45   \n",
      "1        0     74335.27          1.87          1.02          1.29       1.19   \n",
      "2        0     48746.22          1.21          0.70          1.04       2.12   \n",
      "3        0     64416.70          0.75          2.08          2.40       2.02   \n",
      "4        0     71623.20          2.33          0.66          1.97       1.60   \n",
      "\n",
      "   4-3_delta  3-2_delta  2-1_delta  \n",
      "0      -0.79       0.72       0.71  \n",
      "1      -0.85       0.27      -0.10  \n",
      "2      -0.51       0.34       1.08  \n",
      "3       1.33       0.32      -0.38  \n",
      "4      -1.67       1.31      -0.37  \n"
     ]
    }
   ],
   "source": [
    "# Drop non-feature columns\n",
    "columns = df.columns.tolist()\n",
    "encoded_data = df.drop(['id', 'customer_code', 'co_name'], axis=1)\n",
    "print(encoded_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5644371-2240-4ec8-a5c9-52525e121944",
   "metadata": {},
   "source": [
    "## Part 3: Create training, validation and test data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0195535-5592-4f90-936c-f45da0d587ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099, 9) (600, 9) (300, 9)\n",
      "\n",
      "Number of rows in Train dataset: 2099\n",
      "churned\n",
      "0    1983\n",
      "1     116\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of rows in Validate dataset: 600\n",
      "churned\n",
      "0    567\n",
      "1     33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Number of rows in Test dataset: 300\n",
      "churned\n",
      "0    283\n",
      "1     17\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = encoded_data['churned']\n",
    "train_df, test_and_val_data, _, _ = train_test_split(\n",
    "    encoded_data, y, test_size=0.3, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "y = test_and_val_data['churned']\n",
    "val_df, test_df, _, _ = train_test_split(\n",
    "    test_and_val_data, y, test_size=0.333, stratify=y, random_state=0\n",
    ")\n",
    "\n",
    "print(train_df.shape, val_df.shape, test_df.shape)\n",
    "print()\n",
    "print(f'Number of rows in Train dataset: {train_df.shape[0]}')\n",
    "print(train_df['churned'].value_counts())\n",
    "print()\n",
    "print(f'Number of rows in Validate dataset: {val_df.shape[0]}')\n",
    "print(val_df['churned'].value_counts())\n",
    "print()\n",
    "print(f'Number of rows in Test dataset: {test_df.shape[0]}')\n",
    "print(test_df['churned'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9834cc5d-f233-4fb5-b93e-78fb3de9c454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded: s3://machine-learning-for-interview/chapter-03/processed/train.csv, s3://machine-learning-for-interview/chapter-03/processed/val.csv, s3://machine-learning-for-interview/chapter-03/processed/test.csv\n"
     ]
    }
   ],
   "source": [
    "# Prepare CSVs (header=False for train/val, True for test)\n",
    "train_path = f's3://{data_bucket}/{processed_subfolder}/train.csv'\n",
    "val_path = f's3://{data_bucket}/{processed_subfolder}/val.csv'\n",
    "test_path = f's3://{data_bucket}/{processed_subfolder}/test.csv'\n",
    "\n",
    "wr.s3.to_csv(train_df, path=train_path, header=False, index=False, use_threads=True)\n",
    "wr.s3.to_csv(val_df, path=val_path, header=False, index=False, use_threads=True)\n",
    "wr.s3.to_csv(test_df, path=test_path, header=True, index=False, use_threads=True)\n",
    "\n",
    "print(f\"Uploaded: {train_path}, {val_path}, {test_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba96ecd-bddf-4150-a43f-48a017b364f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "train_input = TrainingInput(\n",
    "    s3_data=f's3://{data_bucket}/{processed_subfolder}/train.csv',\n",
    "    content_type='csv'\n",
    ")\n",
    "val_input = TrainingInput(\n",
    "    s3_data=f's3://{data_bucket}/{processed_subfolder}/val.csv',\n",
    "    content_type='csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5f3ff5-c905-451b-98a5-423b3b356787",
   "metadata": {},
   "source": [
    "## Part 4: Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a25484e-7ecc-4437-8a30-1d4091233b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: sagemaker-xgboost-2025-11-16-16-41-15-334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-16 16:41:17 Starting - Starting the training job...\n",
      "2025-11-16 16:41:49 Downloading - Downloading input data...\n",
      "2025-11-16 16:42:14 Downloading - Downloading the training image......\n",
      "2025-11-16 16:43:15 Training - Training image download completed. Training in progress.\n",
      "2025-11-16 16:43:15 Uploading - Uploading generated training model\u001b[34m/miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.191 ip-10-0-244-119.ec2.internal:7 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.213 ip-10-0-244-119.ec2.internal:7 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Failed to parse hyperparameter eval_metric value auc to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Failed to parse hyperparameter objective value binary:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Determined 0 GPU(s) available on the instance.\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Train matrix has 2099 rows and 8 columns\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Validation matrix has 600 rows\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.616 ip-10-0-244-119.ec2.internal:7 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.617 ip-10-0-244-119.ec2.internal:7 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.617 ip-10-0-244-119.ec2.internal:7 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.617 ip-10-0-244-119.ec2.internal:7 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[2025-11-16:16:43:08:INFO] Debug hook created from config\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.668 ip-10-0-244-119.ec2.internal:7 INFO hook.py:427] Monitoring the collections: metrics\u001b[0m\n",
      "\u001b[34m[2025-11-16 16:43:08.672 ip-10-0-244-119.ec2.internal:7 INFO hook.py:491] Hook is writing from the hook with pid: 7\u001b[0m\n",
      "\u001b[34m[0]#011train-auc:0.96983#011validation-auc:0.97205\u001b[0m\n",
      "\u001b[34m[1]#011train-auc:0.97447#011validation-auc:0.98063\u001b[0m\n",
      "\u001b[34m[2]#011train-auc:0.97438#011validation-auc:0.98063\u001b[0m\n",
      "\u001b[34m[3]#011train-auc:0.97459#011validation-auc:0.98025\u001b[0m\n",
      "\u001b[34m[4]#011train-auc:0.97499#011validation-auc:0.97977\u001b[0m\n",
      "\u001b[34m[5]#011train-auc:0.97556#011validation-auc:0.97977\u001b[0m\n",
      "\u001b[34m[6]#011train-auc:0.97579#011validation-auc:0.97988\u001b[0m\n",
      "\u001b[34m[7]#011train-auc:0.97750#011validation-auc:0.97878\u001b[0m\n",
      "\u001b[34m[8]#011train-auc:0.98061#011validation-auc:0.97747\u001b[0m\n",
      "\u001b[34m[9]#011train-auc:0.98079#011validation-auc:0.97774\u001b[0m\n",
      "\u001b[34m[10]#011train-auc:0.98171#011validation-auc:0.97828\u001b[0m\n",
      "\n",
      "2025-11-16 16:43:28 Completed - Training job completed\n",
      "Training seconds: 99\n",
      "Billable seconds: 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "region = boto3.Session().region_name\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# Modern way to get the XGBoost container\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\"       # recommended stable version\n",
    ")\n",
    "\n",
    "estimator = Estimator(\n",
    "    image_uri=container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",   # replacement for m4.xlarge\n",
    "    output_path=f\"s3://{data_bucket}/{subfolder}/output\",\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "estimator.set_hyperparameters(\n",
    "    max_depth=3,\n",
    "    subsample=0.7,\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    num_round=100,\n",
    "    early_stopping_rounds=10,\n",
    "    scale_pos_weight=17\n",
    ")\n",
    "\n",
    "estimator.fit({'train': train_input, 'validation': val_input})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6158d-101c-4235-9067-b039152753d7",
   "metadata": {},
   "source": [
    "## Part 5: Host the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bf0cc82-bd78-4b33-96a9-84791a51da66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: customer-churn\n",
      "INFO:sagemaker:Creating model with name: sagemaker-xgboost-2025-11-16-16-54-07-191\n",
      "INFO:sagemaker:Creating endpoint-config with name customer-churn\n",
      "INFO:sagemaker:Creating endpoint with name customer-churn\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "endpoint_name = \"customer-churn\"\n",
    "\n",
    "# Delete old endpoint\n",
    "try:\n",
    "    sess.delete_endpoint(endpoint_name)\n",
    "    print(\"Existing endpoint deleted.\")\n",
    "    sleep(30)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    serializer=CSVSerializer(),     # modern serializer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005020cf-db67-4f3f-b02b-d9586f4b8cd8",
   "metadata": {},
   "source": [
    "## Part 6: Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dbe8d929-c01d-4d06-ae9d-2517fbf4f4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/sagemaker/base_serializers.py:116: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  has_multiple_rows = len(data) > 0 and self._is_sequence_like(data[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   churned  total_spend  week_minus_4  week_minus_3  week_minus_2  last_week  \\\n",
      "0        0     76897.46          0.56          2.29          1.14       2.23   \n",
      "1        0     19604.63          1.95          2.04          0.82       1.62   \n",
      "2        0     23369.60          1.11          1.54          1.55       1.14   \n",
      "3        1     40709.47          2.40          1.87          0.07       0.61   \n",
      "4        0     69953.52          2.01          1.20          1.05       1.41   \n",
      "5        0     71939.07          0.54          1.17          0.21       2.29   \n",
      "6        0     45930.53          0.08          1.43          0.41       1.34   \n",
      "7        0     47080.25          1.54          0.68          0.80       0.54   \n",
      "8        0     35506.83          1.37          0.93          1.70       0.67   \n",
      "9        0     39188.12          0.40          1.86          0.10       0.82   \n",
      "\n",
      "   4-3_delta  3-2_delta  2-1_delta  prediction  \n",
      "0       1.73      -1.15       1.09           0  \n",
      "1       0.09      -1.22       0.80           0  \n",
      "2       0.43       0.01      -0.41           0  \n",
      "3      -0.53      -1.80       0.54           1  \n",
      "4      -0.81      -0.15       0.36           0  \n",
      "5       0.63      -0.96       2.08           0  \n",
      "6       1.35      -1.02       0.93           0  \n",
      "7      -0.86       0.12      -0.26           0  \n",
      "8      -0.44       0.77      -1.03           0  \n",
      "9       1.46      -1.76       0.72           0  \n"
     ]
    }
   ],
   "source": [
    "def get_prediction(row):\n",
    "    # Predict probability, threshold at 0.5\n",
    "    prob = float(predictor.predict(row[1:]).decode('utf-8'))  # row[1:] skips target\n",
    "    return 1 if prob > 0.5 else 0\n",
    "\n",
    "# Load test data\n",
    "test_data = wr.s3.read_csv(path=test_path, use_threads=True)\n",
    "\n",
    "# Apply predictions\n",
    "test_data['prediction'] = test_data.apply(get_prediction, axis=1)\n",
    "print(test_data.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b97db5e1-c43d-480f-b45d-1523e2976f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "churned\n",
      "0    283\n",
      "1     17\n",
      "Name: count, dtype: int64\n",
      "prediction\n",
      "0    266\n",
      "1     34\n",
      "Name: count, dtype: int64\n",
      "0.9433333333333334\n"
     ]
    }
   ],
   "source": [
    "print(test_data['churned'].value_counts())\n",
    "print(test_data['prediction'].value_counts())\n",
    "print(metrics.accuracy_score(test_data['churned'], test_data['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7afe36e6-58db-4c0e-8adc-b14ffca56204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266  17]\n",
      " [  0  17]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(test_data['churned'], test_data['prediction']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8123d6b9-d2be-4bd5-b20f-8edecd1a2222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 1]\n",
      " [1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Demo confusion matrix (assuming binary; adjust if multi-class)\n",
    "y_demo = [1, 0, 0, 0, 0, 0, 0, 0, 0, 1]  # Fixed to binary example\n",
    "pred_demo = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
    "print(metrics.confusion_matrix(y_demo, pred_demo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a349c22-3ebb-487e-a41d-f971e0612da0",
   "metadata": {},
   "source": [
    "## Remove the Endpoint (optional)\n",
    "Comment out this cell to remove the endpoint if you want the endpoint to exist after \"run all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23c39671-4b72-4b21-9811-889917c899cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: customer-churn\n"
     ]
    }
   ],
   "source": [
    "# Cleanup\n",
    "sess.delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
